{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "# Store the API key in a variable.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two common breeds of cats are the Siamese and the Persian.\n",
      "\n",
      "It is difficult to determine which shed the least without more context. However, in general, reptiles such as snakes and turtles tend to shed less frequently than mammals such as dogs and cats. Additionally, animals with short fur or hair may shed less than those with long fur or hair.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.3)\n",
    "\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"What are two common breeds of cats?\"\n",
    "\n",
    "# Pass the query to the invoke method which will make a prediction based on the query, and print the result.\n",
    "result = llm.invoke(query)\n",
    "print(result.content)\n",
    "\n",
    "print()\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"Which of those shed the least\"\n",
    "\n",
    "\n",
    "# Pass the query to the invoke method which will make a prediction based on the query, and print the result.\n",
    "result = llm.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for conversational memory.\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What are two common breeds of cats?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What are two common breeds of cats?', 'history': '', 'response': 'Two common breeds of cats are the domestic shorthair and the Persian. The domestic shorthair is a mixed breed cat with a short coat and a variety of colors and patterns. The Persian is a longhaired breed known for its flat face and luxurious coat.'}\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What are two common breeds of cats?\n",
      "AI: Two common breeds of cats are the domestic shorthair and the Persian. The domestic shorthair is a mixed breed cat with a short coat and a variety of colors and patterns. The Persian is a longhaired breed known for its flat face and luxurious coat.\n",
      "Human: Which of those shed the least\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Which of those shed the least', 'history': 'Human: What are two common breeds of cats?\\nAI: Two common breeds of cats are the domestic shorthair and the Persian. The domestic shorthair is a mixed breed cat with a short coat and a variety of colors and patterns. The Persian is a longhaired breed known for its flat face and luxurious coat.', 'response': 'The Persian cat tends to shed less than the domestic shorthair due to its long, thick coat that is less prone to shedding. However, regular grooming is still necessary to prevent matting and tangles in their fur.'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.3)\n",
    "\n",
    "\n",
    "# Initialize an object for conversational memory.\n",
    "buffer = ConversationBufferMemory()\n",
    "\n",
    "# Create the chain for conversation, using a ConversationBufferMemory object.\n",
    "conversation = ConversationChain(llm=llm, verbose=True, memory=buffer)\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"What are two common breeds of cats?\"\n",
    "\n",
    "# Pass the query to the invoke method which will make a prediction based on the query, and print the result.\n",
    "result = conversation.invoke(input=query)\n",
    "print(result)\n",
    "\n",
    "print()\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"Which of those shed the least\"\n",
    "\n",
    "\n",
    "# Pass the query to the invoke method which will make a prediction based on the query, and print the result.\n",
    "result = conversation.invoke(input=query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are two common breeds of cats?\n",
      "\n",
      "\n",
      "Assistant: Two common breeds of cats are the domestic shorthair and the Persian cat. The domestic shorthair is a mixed breed cat with a short coat and a variety of colors and patterns. The Persian cat is known for its long, luxurious coat and flat face. Both breeds are popular choices for pet owners due to their friendly and affectionate nature.\n",
      "User: \"Which of those shed the least\"\n",
      "\n",
      "\n",
      "Assistant: The Persian cat tends to shed less than the domestic shorthair due to its long coat that is less prone to shedding. However, it's important to note that all cats shed to some extent, so regular grooming is still necessary to keep their coat healthy and reduce shedding.\n",
      "User: q\n",
      "\n",
      "See ya\n"
     ]
    }
   ],
   "source": [
    "buffer = ConversationBufferMemory()\n",
    "# Create the chain for conversation, using a ConversationBufferMemory object.\n",
    "conversation = ConversationChain(llm=llm, verbose=False, memory=buffer)\n",
    "while True:\n",
    "    query = input(\"User: \")\n",
    "    print()\n",
    "    if query == \"q\":\n",
    "        print(\"See ya\")\n",
    "        break\n",
    "    print()\n",
    "    print(\"Assistant:\", conversation.predict(input=query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summaries as memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for summary-based memory.\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: \"What are two common breeds of cats?\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: \"What are two common breeds of cats?\"\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: Two common breeds of cats are the domestic shorthair and the Siamese. Domestic shorthair cats are a mixed breed with a short coat, while Siamese cats are known for their striking blue almond-shaped eyes and pointed coloration on their ears, face, paws, and tail.\n",
      "User: \"Which of those shed the least?\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human asks the AI to name two common breeds of cats. The AI responds that the domestic shorthair and Siamese are common breeds, describing their characteristics.\n",
      "Human: \"Which of those shed the least?\"\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: The domestic shorthair cat typically sheds less than the Siamese cat. Domestic shorthairs have short, dense coats that require minimal grooming compared to the Siamese, which has a short, fine coat that sheds more frequently. However, it's important to note that all cats shed to some extent, so regular grooming is still recommended for both breeds.\n",
      "User: \"Which one tends to weigh more?\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human asks the AI to name two common breeds of cats. The AI responds that the domestic shorthair and Siamese are common breeds, describing their characteristics. The human then asks which of those sheds the least, and the AI explains that the domestic shorthair typically sheds less than the Siamese due to their different coat types. Regular grooming is still recommended for both breeds despite shedding.\n",
      "Human: \"Which one tends to weigh more?\"\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: The domestic shorthair tends to weigh more on average compared to the Siamese breed. Domestic shorthairs can range from 8-16 pounds, while Siamese cats typically weigh between 6-10 pounds. However, it's important to remember that individual cats may vary in weight regardless of breed.\n",
      "User: q\n",
      "\n",
      "See ya\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model for summaries.\n",
    "summary_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                         model_name=OPENAI_MODEL,\n",
    "                         temperature=0.0)\n",
    "\n",
    "# Initialize the model for output.\n",
    "chat_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                      model_name=OPENAI_MODEL,\n",
    "                      temperature=0.7)\n",
    "\n",
    "# Initialize an object for conversational memory.\n",
    "buffer = ConversationSummaryMemory(llm=summary_llm)\n",
    "\n",
    "\n",
    "# Create the chain for conversation, using a ConversationBufferMemory object.\n",
    "conversation = ConversationChain(llm=chat_llm, memory=buffer, verbose=True)\n",
    "while True:\n",
    "    query = input(\"User: \")\n",
    "    print()\n",
    "    if query == \"q\":\n",
    "        print(\"See ya\")\n",
    "        break\n",
    "    print()\n",
    "    result = conversation.predict(input=query)\n",
    "    print(\"Assistant:\", result)\n",
    "\n",
    "# # Define a query as a string.\n",
    "\n",
    "\n",
    "# # Pass the query to the predict method, and print the result.\n",
    "\n",
    "\n",
    "# print()\n",
    "\n",
    "# # Define a query as a string.\n",
    "\n",
    "\n",
    "# # Pass the query to the predict method, and print the result.\n",
    "\n",
    "\n",
    "# # Define a query as a string.\n",
    "\n",
    "\n",
    "# # Pass the query to the predict method, and print the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity-based Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for entity-based memory.\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['entities', 'history', 'input'], template='You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n{entities}\\n\\nCurrent conversation:\\n{history}\\nLast line:\\nHuman: {input}\\nYou:')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENTITY_MEMORY_CONVERSATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: \"There are two cats up for adoption: Godric is a Maine Coon, and Luna is a Bombay.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Godric': '', 'Maine Coon': '', 'Luna': '', 'Bombay': ''}\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Last line:\n",
      "Human: \"There are two cats up for adoption: Godric is a Maine Coon, and Luna is a Bombay.\"\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: That's great to hear! Both Godric, the Maine Coon, and Luna, the Bombay, are beautiful cat breeds with their own unique characteristics. Maine Coons are known for their large size, tufted ears, and friendly personalities, while Bombays are known for their sleek black coat and affectionate nature. It's wonderful that these cats are up for adoption, and I'm sure they will find loving homes soon. If you have any questions about either breed or need any advice on adopting a cat, feel free to ask!\n",
      "User:  \"Which of those cats probably has shorter fur?\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Godric': 'Godric is a Maine Coon cat.', 'Luna': 'Luna is a Bombay cat breed.'}\n",
      "\n",
      "Current conversation:\n",
      "Human: \"There are two cats up for adoption: Godric is a Maine Coon, and Luna is a Bombay.\"\n",
      "AI: That's great to hear! Both Godric, the Maine Coon, and Luna, the Bombay, are beautiful cat breeds with their own unique characteristics. Maine Coons are known for their large size, tufted ears, and friendly personalities, while Bombays are known for their sleek black coat and affectionate nature. It's wonderful that these cats are up for adoption, and I'm sure they will find loving homes soon. If you have any questions about either breed or need any advice on adopting a cat, feel free to ask!\n",
      "Last line:\n",
      "Human:  \"Which of those cats probably has shorter fur?\"\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: Luna, the Bombay cat, probably has shorter fur compared to Godric, the Maine Coon. Bombay cats are known for their sleek, short coat that requires minimal grooming, while Maine Coons have a longer, thicker coat that may need more maintenance. If you're looking for a cat with shorter fur that is easy to care for in terms of grooming, Luna would be a great choice!\n",
      "User: \"Which cat probably has a calmer temperament?\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{}\n",
      "\n",
      "Current conversation:\n",
      "Human: \"There are two cats up for adoption: Godric is a Maine Coon, and Luna is a Bombay.\"\n",
      "AI: That's great to hear! Both Godric, the Maine Coon, and Luna, the Bombay, are beautiful cat breeds with their own unique characteristics. Maine Coons are known for their large size, tufted ears, and friendly personalities, while Bombays are known for their sleek black coat and affectionate nature. It's wonderful that these cats are up for adoption, and I'm sure they will find loving homes soon. If you have any questions about either breed or need any advice on adopting a cat, feel free to ask!\n",
      "Human:  \"Which of those cats probably has shorter fur?\"\n",
      "AI: Luna, the Bombay cat, probably has shorter fur compared to Godric, the Maine Coon. Bombay cats are known for their sleek, short coat that requires minimal grooming, while Maine Coons have a longer, thicker coat that may need more maintenance. If you're looking for a cat with shorter fur that is easy to care for in terms of grooming, Luna would be a great choice!\n",
      "Last line:\n",
      "Human: \"Which cat probably has a calmer temperament?\"\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: In general, Maine Coons like Godric are known for their calm and friendly temperament. They are often described as gentle giants and are known to be affectionate and laid-back. On the other hand, Bombays like Luna are also known for their affectionate nature, but they can be more playful and energetic compared to Maine Coons. Both breeds can be wonderful companions, but if you're looking for a cat with a calmer temperament, Godric, the Maine Coon, would likely be the better choice.\n",
      "User: q\n",
      "\n",
      "See ya\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model for entities.\n",
    "entity_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                        model_name=OPENAI_MODEL,\n",
    "                        temperature=0.0)\n",
    "\n",
    "# Initialize the model for output.\n",
    "chat_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                      model_name=OPENAI_MODEL,\n",
    "                      temperature=0.7)\n",
    "\n",
    "\n",
    "# Initialize an object for conversational memory.\n",
    "buffer = ConversationEntityMemory(llm=entity_llm)\n",
    "\n",
    "# Create the chain for conversation, using a ConversationBufferMemory object.\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_llm, \n",
    "    memory=buffer, \n",
    "    verbose=True, \n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    ")\n",
    "\n",
    "while True:\n",
    "    query = input(\"User: \")\n",
    "    print()\n",
    "    if query == \"q\":\n",
    "        print(\"See ya\")\n",
    "        break\n",
    "    print()\n",
    "    result = conversation.predict(input=query)\n",
    "    print(\"Assistant:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
