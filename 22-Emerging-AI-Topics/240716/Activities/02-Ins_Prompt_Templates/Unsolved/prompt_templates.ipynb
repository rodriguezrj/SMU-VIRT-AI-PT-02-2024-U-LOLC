{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "# Store the API key in a variable.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for human and system messages.\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model.\n",
    "llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.3)\n",
    "\n",
    "# Create a list containing a system message and a human message.\n",
    "messages = [\n",
    "    SystemMessage(content='You are an athletic trainer.'),\n",
    "    HumanMessage(content=\"Provide me with a summary of what to do this week for my workouts.\")\n",
    "]\n",
    "\n",
    "# Provide the messages to the LLM and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an athletic trainer.'),\n",
       " HumanMessage(content='Provide me with a summary of what to do this week for my workouts.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! This week, focus on a combination of strength training, cardiovascular exercise, and flexibility work. Here is a suggested workout plan for the week:\n",
      "\n",
      "Monday:\n",
      "- Warm up with 5-10 minutes of light cardio (jogging, cycling, etc.)\n",
      "- Strength training: focus on lower body exercises such as squats, lunges, and deadlifts\n",
      "- Cardio: 20-30 minutes of moderate-intensity cardio (running, biking, elliptical)\n",
      "- Cool down with stretching for 10-15 minutes\n",
      "\n",
      "Tuesday:\n",
      "- Active recovery day: light yoga, stretching, or a gentle walk\n",
      "\n",
      "Wednesday:\n",
      "- Warm up with 5-10 minutes of light cardio\n",
      "- Strength training: focus on upper body exercises such as push-ups, rows, and shoulder presses\n",
      "- Cardio: 20-30 minutes of high-intensity interval training (HIIT) or circuit training\n",
      "- Cool down with stretching for 10-15 minutes\n",
      "\n",
      "Thursday:\n",
      "- Active recovery day: light yoga, stretching, or a gentle walk\n",
      "\n",
      "Friday:\n",
      "- Warm up with 5-10 minutes of light cardio\n",
      "- Full-body strength training: incorporate exercises that target multiple muscle groups such as planks, burpees, and kettlebell swings\n",
      "- Cardio: 20-30 minutes of steady-state cardio (swimming, rowing, etc.)\n",
      "- Cool down with stretching for 10-15 minutes\n",
      "\n",
      "Saturday:\n",
      "- Rest day or light activity such as hiking or biking\n",
      "\n",
      "Sunday:\n",
      "- Active recovery day: light yoga, stretching, or a gentle walk\n",
      "\n",
      "Remember to listen to your body, stay hydrated, and fuel your workouts with nutritious foods. Adjust the intensity and duration of your workouts based on your fitness level and goals. If you have any specific health concerns or injuries, consult with a healthcare provider or fitness professional before starting a new workout routine.\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! This week, focus on a combination of strength training, cardiovascular exercise, and flexibility work. Here is a suggested workout plan for the week:\\n\\nMonday:\\n- Warm up with 5-10 minutes of light cardio (jogging, cycling, etc.)\\n- Strength training: focus on lower body exercises such as squats, lunges, and deadlifts\\n- Cardio: 20-30 minutes of moderate-intensity cardio (running, biking, elliptical)\\n- Cool down with stretching for 10-15 minutes\\n\\nTuesday:\\n- Active recovery day: light yoga, stretching, or a gentle walk\\n\\nWednesday:\\n- Warm up with 5-10 minutes of light cardio\\n- Strength training: focus on upper body exercises such as push-ups, rows, and shoulder presses\\n- Cardio: 20-30 minutes of high-intensity interval training (HIIT) or circuit training\\n- Cool down with stretching for 10-15 minutes\\n\\nThursday:\\n- Active recovery day: light yoga, stretching, or a gentle walk\\n\\nFriday:\\n- Warm up with 5-10 minutes of light cardio\\n- Full-body strength training: incorporate exercises that target multiple muscle groups such as planks, burpees, and kettlebell swings\\n- Cardio: 20-30 minutes of steady-state cardio (swimming, rowing, etc.)\\n- Cool down with stretching for 10-15 minutes\\n\\nSaturday:\\n- Rest day or light activity such as hiking or biking\\n\\nSunday:\\n- Active recovery day: light yoga, stretching, or a gentle walk\\n\\nRemember to listen to your body, stay hydrated, and fuel your workouts with nutritious foods. Adjust the intensity and duration of your workouts based on your fitness level and goals. If you have any specific health concerns or injuries, consult with a healthcare provider or fitness professional before starting a new workout routine.', response_metadata={'token_usage': {'completion_tokens': 375, 'prompt_tokens': 32, 'total_tokens': 407}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7a468105-97f8-4b76-8f8f-83b46bec00d6-0', usage_metadata={'input_tokens': 32, 'output_tokens': 375, 'total_tokens': 407})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Templates for Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Additional imports for prompt template and LLM chain.\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialize the model.\n",
    "llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.3)\n",
    "\n",
    "\n",
    "# Define the format for the template.\n",
    "format = \"\"\"\n",
    "You are a history tutor. Answer only questions that would be covered in a history course.\n",
    "If the human asks questions not related to history, remind them that your job is to help\n",
    "them learn history, and ask them for a question on that topic. If they ask a question which\n",
    "there is not enough information to answer, tell them you don't know and don't make up an \n",
    "answer.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Construct the prompt template.\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], template=\"\\nYou are a history tutor. Answer only questions that would be covered in a history course.\\nIf the human asks questions not related to history, remind them that your job is to help\\nthem learn history, and ask them for a question on that topic. If they ask a question which\\nthere is not enough information to answer, tell them you don't know and don't make up an \\nanswer.\\n\\nQuestion: {query}\\n\\nAnswer: \\n\")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Construct a chain using this template.\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the query as a string.\n",
    "query = {'query' : \"Why were the 1980 summer Olympics boycotted?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run the chain using the query as input and print the result.\n",
    "result = chain.invoke(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 1980 summer Olympics were boycotted by a number of countries, primarily in response to the Soviet Union's invasion of Afghanistan in December 1979. The United States led a boycott of the games, with over 60 countries following suit in protest of the Soviet Union's actions.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but my expertise is in history. Do you have a question related to history that I can help you with?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print()\n",
    "\n",
    "# Define the query as a string.\n",
    "query = {'query' : \"WHy is the sky blue?\"}\n",
    "\n",
    "# Run the chain using the query as input and print the result.\n",
    "result = chain.invoke(query)\n",
    "result['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates for Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional import for the template.\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model.\n",
    "llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.3)\n",
    "\n",
    "# Define a prefix that explains the prompt.\n",
    "prefix = \"\"\"\n",
    "Here are examples between a human and AI. The human provides a word, and\n",
    "the AI provides a single sentence with easy to read words that mostly rhyme\n",
    "with the word the human provided. The sentence does not have to include the \n",
    "original word. For example:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create examples.\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"rat\",\n",
    "        \"answer\": \"The cat sat next to the bat.\"\n",
    "    }, {\n",
    "        \"query\": \"frog\",\n",
    "        \"answer\": \"A dog hops a log in the bog.\"\n",
    "    }, {\n",
    "        \"query\": \"ten\",\n",
    "        \"answer\": \"Ben sent ten hens to the glen.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a format for the examples.\n",
    "example_format = \"\"\"\n",
    "Human: {query}\n",
    "AI: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template for the examples.\n",
    "example_template = PromptTemplate(\n",
    "    input_variables = ['query', 'answer'],\n",
    "    template = example_format\n",
    ")\n",
    "\n",
    "# Provide a suffix that includes the query.\n",
    "suffix = \"\"\"\n",
    "Human: {query}\n",
    "AI: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the few shot prompt template.\n",
    "prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_template,\n",
    "    input_variables=['query'],\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotPromptTemplate(input_variables=['query'], examples=[{'query': 'rat', 'answer': 'The cat sat next to the bat.'}, {'query': 'frog', 'answer': 'A dog hops a log in the bog.'}, {'query': 'ten', 'answer': 'Ben sent ten hens to the glen.'}], example_prompt=PromptTemplate(input_variables=['answer', 'query'], template='\\nHuman: {query}\\nAI: {answer}\\n'), suffix='\\nHuman: {query}\\nAI: \\n', prefix='\\nHere are examples between a human and AI. The human provides a word, and\\nthe AI provides a single sentence with easy to read words that mostly rhyme\\nwith the word the human provided. The sentence does not have to include the \\noriginal word. For example:\\n')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradleywise/anaconda3/envs/dev/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the slime, a mime did a crime.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a chain using this template.\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Define the query as a string.\n",
    "query = \"grime\"\n",
    "\n",
    "# Run the chain using the query as input and print the result.\n",
    "chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradleywise/anaconda3/envs/dev/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the slime, I rhyme about the time.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'''\n",
    "Here are examples between a human and AI. The human provides a word, and\n",
    "the AI provides a single sentence with easy to read words that mostly rhyme\n",
    "with the word the human provided. The sentence does not have to include the \n",
    "original word. For example:\n",
    "\n",
    "\"Human\": \"rat\",\n",
    "\"AI\": \"The cat sat next to the bat.\"\n",
    "\"Human\": \"frog\",\n",
    "\"AI\": \"A dog hops a log in the bog.\"\n",
    "\"Human\": \"ten\",\n",
    "\"AI\": \"Ben sent ten hens to the glen.\"\n",
    "\n",
    "Human: {query}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "AI: \n",
    "'''\n",
    "\n",
    "\n",
    "query = 'grime'\n",
    "llm.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
