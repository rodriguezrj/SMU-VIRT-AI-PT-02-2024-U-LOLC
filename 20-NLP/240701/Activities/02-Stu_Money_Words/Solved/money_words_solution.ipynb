{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/bradleywise/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import nltk, numpy and pandas.\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import Reuters\n",
    "from nltk.corpus import reuters\n",
    "# Import TfidfVectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "\n",
    "# Download the Reuters dataset\n",
    "nltk.download(\"reuters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the Articles About Money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "# Get the categories\n",
    "print(reuters.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of news articles about money: 883\n"
     ]
    }
   ],
   "source": [
    "# Get all the \"fileids\" in the \"money-fx\" and \"money-supply\" categories.\n",
    "categories = [\"money-fx\", \"money-supply\"]\n",
    "docs_id = reuters.fileids()\n",
    "\n",
    "# Use a list comprehension or for loop to get the all the fieldids.\n",
    "money_news_ids = [\n",
    "    doc\n",
    "    for doc in docs_id\n",
    "    if categories[0] in reuters.categories(doc)\n",
    "    or categories[1] in reuters.categories(doc)\n",
    "]\n",
    "\n",
    "# Print the total number of news articles about money.\n",
    "print(f\"Total number of news articles about money: {len(money_news_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.S. BANKS LIKELY TO LIFT PRIME RATES AGAIN SOON\n",
      "  Major U.S. banks may lift prime\n",
      "  lending rates again within days due to recent increases in\n",
      "  their borrowing costs and speculation the Federal Reserve is\n",
      "  nudging up interest rates to help the dollar, economists said.\n",
      "      In what was the first prime rate boost since mid-1984, most\n",
      "  banks in early April lifted their rates a quarter point to\n",
      "  7-3/4 pct, citing a reduced gap between the prime and their own\n",
      "  cost of money. That spread has narrowed again.\n",
      "      \"A prime rate increase could happen as soon as tonight,\"\n",
      "  said Robert Brusca of Nikko Securities Co International Inc.\n",
      "      Brusca said a quarter-point prime rate rise to eight pct is\n",
      "  justified because the spread between banks' cost of funds and\n",
      "  the prime rate has narrowed to less than three quarters of a\n",
      "  percentage point.\n",
      "      He said that spread had averaged around 1.4 percentage\n",
      "  points since last October until it fell below one point and\n",
      "  triggered the April prime rate rise at most banks.\n",
      "      \"We could easily have another prime rate increase as soon\n",
      "  as this week,\" said David Jones of Aubrey G. Lanston and Co.\n",
      "      \"We've got a fairly good chance of a prime rate rise in the\n",
      "  near future,\" said Allan Leslie of Discount Corp.\n",
      "      \"Based on the spread between the prime rate and funding\n",
      "  costs, you would ordinarily see a prime rate increase now,\"\n",
      "  said Harold Nathan, economist at Wells Fargo Bank.\n",
      "      However, he said banks may be reluctant to lift the prime\n",
      "  because that would dampen already fairly weak business loan\n",
      "  demand and because some are not sure the Fed will maintain\n",
      "  recent upward pressure on money market interest rates.\n",
      "      Nathan believes the Fed has let market pressures lift\n",
      "  short-term rates in recent days to help the ailing dollar. He\n",
      "  said \"if there is widespread belief money market rates will\n",
      "  stay high, a prime rate rise could occur at any time.\"\n",
      "      Fed officials have long expressed concern that too steep a\n",
      "  dollar drop could help rekindle U.S. inflation. As the dollar\n",
      "  fell to a 40-year low against the yen Friday, currency traders\n",
      "  said the Fed and other central banks supported the dollar.\n",
      "      In addition to buying dollars outright, another way to\n",
      "  stabilize the U.S. currency would be for the Fed to push U.S.\n",
      "  interest rates higher relative to overseas rates.\n",
      "      Based particularly on the Fed's reserve management actions\n",
      "  on Friday and today, Nathan of Wells Fargo said \"it has become\n",
      "  clear that the Fed is not fully resisting upward rate pressure\n",
      "  in the market. It is supplying fewer reserves than are needed.\"\n",
      "      Bank funding costs and other short and long-term interest\n",
      "  rates rose sharply Friday and today on heightened speculation\n",
      "  that the Fed is gently firming monetary policy.\n",
      "      That was because the Fed supplied far fewer reserves in the\n",
      "  market than most economists had expected.\n",
      "      On Friday, the Fed added reserves indirectly and in small\n",
      "  amounts via one billion dlrs of customer repurchase agreements\n",
      "  with the Federal funds rate at which banks lend to one another\n",
      "  high at 6-5/16 pct. With funds trading even higher at 6-1/2 pct\n",
      "  today, the Fed arranged only a slightly larger 1.5 billion dlr\n",
      "  round of customer repurchase agreements.\n",
      "      \"The Fed's actions on Friday and today show that it is\n",
      "  offering only token resistance to upward funds rate pressures,\"\n",
      "  said Jones of Lanston.\n",
      "      \"The Fed is focusing its policy attention mainly on the\n",
      "  need to defend the dollar,\" Jones said. He believes it is\n",
      "  merely shading policy toward restraint now, \"but to have a\n",
      "  major impact on the dollar, the Fed will have to tighten policy\n",
      "  overtly at some point.\"\n",
      "      Jones expects the Fed to foster higher market rates by\n",
      "  becoming more restrictive in supplying reserves and, within\n",
      "  four to six weeks, to raise its discount rate from 5-1/2 pct.\n",
      "      Jones said a U.S. discount rate increase to six pct might\n",
      "  well be accompanied by West German and Japanese rate cuts to\n",
      "  further aid the dollar.\n",
      "      Given likely Fed policy firming, he said both the yield on\n",
      "  30-year Treasury bonds (about 8.30 pct now) and the prime rate\n",
      "  may be at 8-1/2 pct at end-June and nine pct by year's end.\n",
      "      \"The jury is still out on whether the Fed is tightening\n",
      "  policy to defend the dollar,\" said Leslie of Discount Corp. He\n",
      "  said tax-date pressures have been pushing up Fed funds lately.\n",
      "  Leslie said Fed actions and reserve data once these pressures\n",
      "  abate will show whether or not it is firming policy.  \n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a list comprehension or for loop to retrieve the text from the corpus containing all the news articles about money.\n",
    "money_news = [reuters.raw(doc) for doc in money_news_ids]\n",
    "\n",
    "# Print a sample article\n",
    "print(money_news[78])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the TF-IDF Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the TfidfVectorizer and define the English stopwords to be ignored.\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "# Tokenize the articles about money into numerical features.\n",
    "X = vectorizer.fit_transform(money_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(883, 7356)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6495348"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "883*7356"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       ...,\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.065751, 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold the words using the vectorizer.get_feature_names_out()\n",
    "words = list(vectorizer.get_feature_names_out())\n",
    "# Create a list to hold the frequency using np.ravel(X.sum(axis=0))\n",
    "frequency = list(np.ravel(X.sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>3.867438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>1.956415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000</td>\n",
       "      <td>0.101317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002</td>\n",
       "      <td>0.076203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003</td>\n",
       "      <td>0.171025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>004</td>\n",
       "      <td>0.188415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>006913</td>\n",
       "      <td>0.055155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>006916</td>\n",
       "      <td>0.076118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>007050</td>\n",
       "      <td>0.076118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>007100</td>\n",
       "      <td>0.055155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Frequency\n",
       "0      00   3.867438\n",
       "1     000   1.956415\n",
       "2    0000   0.101317\n",
       "3     002   0.076203\n",
       "4     003   0.171025\n",
       "5     004   0.188415\n",
       "6  006913   0.055155\n",
       "7  006916   0.076118\n",
       "8  007050   0.076118\n",
       "9  007100   0.055155"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of the TF–IDF weights for each word in the working corpus.\n",
    "money_news_df = pd.DataFrame({\n",
    "    \"Word\": words,\n",
    "    \"Frequency\": frequency})\n",
    "\n",
    "# Display the DataFrame\n",
    "money_news_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7346</th>\n",
       "      <td>zero</td>\n",
       "      <td>0.381634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>zhejiang</td>\n",
       "      <td>0.117760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.610475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>zimoil</td>\n",
       "      <td>0.119876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>zoete</td>\n",
       "      <td>0.055550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>zone</td>\n",
       "      <td>0.440092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7352</th>\n",
       "      <td>zones</td>\n",
       "      <td>1.756150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>zurich</td>\n",
       "      <td>0.431580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7354</th>\n",
       "      <td>zwermann</td>\n",
       "      <td>0.057754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7355</th>\n",
       "      <td>üside</td>\n",
       "      <td>0.060045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Frequency\n",
       "7346      zero   0.381634\n",
       "7347  zhejiang   0.117760\n",
       "7348  zimbabwe   0.610475\n",
       "7349    zimoil   0.119876\n",
       "7350     zoete   0.055550\n",
       "7351      zone   0.440092\n",
       "7352     zones   1.756150\n",
       "7353    zurich   0.431580\n",
       "7354  zwermann   0.057754\n",
       "7355     üside   0.060045"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "money_news_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>54.918051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mln</td>\n",
       "      <td>51.533825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bank</td>\n",
       "      <td>49.568996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stg</td>\n",
       "      <td>47.236863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>billion</td>\n",
       "      <td>43.544274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pct</td>\n",
       "      <td>41.917193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dollar</td>\n",
       "      <td>37.178790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fed</td>\n",
       "      <td>36.860352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dlrs</td>\n",
       "      <td>36.273205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>market</td>\n",
       "      <td>35.086673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Frequency\n",
       "0     said  54.918051\n",
       "1      mln  51.533825\n",
       "2     bank  49.568996\n",
       "3      stg  47.236863\n",
       "4  billion  43.544274\n",
       "5      pct  41.917193\n",
       "6   dollar  37.178790\n",
       "7      fed  36.860352\n",
       "8     dlrs  36.273205\n",
       "9   market  35.086673"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by word frequency in descending order and reset the index.\n",
    "money_news_df = money_news_df.sort_values(by=[\"Frequency\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the top 10 words\n",
    "money_news_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>54.918051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mln</td>\n",
       "      <td>51.533825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bank</td>\n",
       "      <td>49.568996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stg</td>\n",
       "      <td>47.236863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>billion</td>\n",
       "      <td>43.544274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pct</td>\n",
       "      <td>41.917193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dollar</td>\n",
       "      <td>37.178790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fed</td>\n",
       "      <td>36.860352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dlrs</td>\n",
       "      <td>36.273205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>market</td>\n",
       "      <td>35.086673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Frequency\n",
       "0     said  54.918051\n",
       "1      mln  51.533825\n",
       "2     bank  49.568996\n",
       "3      stg  47.236863\n",
       "4  billion  43.544274\n",
       "5      pct  41.917193\n",
       "6   dollar  37.178790\n",
       "7      fed  36.860352\n",
       "8     dlrs  36.273205\n",
       "9   market  35.086673"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative: Create a DataFrame of the TF–IDF weights for each term in the working corpus. \n",
    "money_news_df = pd.DataFrame(\n",
    "    list(zip(vectorizer.get_feature_names_out(), np.ravel(X.sum(axis=0)))),\n",
    "    columns=[\"Word\", \"Frequency\"],\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by word frequency in descending order and reset the index..\n",
    "money_news_df = money_news_df.sort_values(by=[\"Frequency\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the top 10 words\n",
    "money_news_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many documents contains a specific word or group of words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function called `retrieve_docs(terms)`that searches the \"money_news_ids\" list \n",
    "# and retrieves the number of articles for a given word or group of words.\n",
    "def retrieve_docs(terms):\n",
    "    \"\"\"\n",
    "    Retrieve a list of document IDs that contain at least one of the specified terms.\n",
    "\n",
    "    This function searches through a collection of documents represented by 'money_news_ids'\n",
    "    to identify documents that contain at least one of the provided terms. It utilizes the\n",
    "    NLTK Reuters corpus and tokenizes each document to find matches based on the lowercase\n",
    "    representation of words.\n",
    "\n",
    "    Parameters:\n",
    "    terms (list of str): A list of terms to search for within the documents.\n",
    "\n",
    "    Returns:\n",
    "    list of str: A list of document IDs that contain at least one of the specified terms.\n",
    "\n",
    "    Example:\n",
    "    >>> retrieve_docs(['stock', 'market', 'invest'])\n",
    "    ['doc1', 'doc3', 'doc5']\n",
    "    \"\"\"\n",
    "    # Create an empty list to hold the results.\n",
    "    result_docs = []\n",
    "    # Use a for loop to loop through the money_news_ids.\n",
    "    for doc_id in money_news_ids:\n",
    "        # Use a list comprehension or a for loop to extract words from the document using reuters.words(doc_id)) \n",
    "        # then populates list comprehension using a conditional statement that checks for any words in \n",
    "        # lowercase matching the \"terms\" passed to the function.\n",
    "        found_terms = [word for word in reuters.words(doc_id) if any(term in word.lower() for term in terms)]\n",
    "        # Use a conditional statement that checks whether there are is at least one term from the input \n",
    "        # list that was found in the document. If it is found, the append the article id to the list. \n",
    "        if len(found_terms) > 0:\n",
    "            result_docs.append(doc_id)\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Question 1: How many articles talk about Yen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/14890',\n",
       " 'test/14913',\n",
       " 'test/14987',\n",
       " 'test/15431',\n",
       " 'test/15442',\n",
       " 'test/15450',\n",
       " 'test/15453',\n",
       " 'test/15460',\n",
       " 'test/15625',\n",
       " 'test/15677',\n",
       " 'test/15689',\n",
       " 'test/16053',\n",
       " 'test/16066',\n",
       " 'test/16067',\n",
       " 'test/16068',\n",
       " 'test/16069',\n",
       " 'test/16072',\n",
       " 'test/16106',\n",
       " 'test/16111',\n",
       " 'test/16177',\n",
       " 'test/16189',\n",
       " 'test/16190',\n",
       " 'test/16565',\n",
       " 'test/16744',\n",
       " 'test/16754',\n",
       " 'test/16755',\n",
       " 'test/16779',\n",
       " 'test/17041',\n",
       " 'test/17044',\n",
       " 'test/17047',\n",
       " 'test/17871',\n",
       " 'test/17980',\n",
       " 'test/18360',\n",
       " 'test/18363',\n",
       " 'test/18370',\n",
       " 'test/18674',\n",
       " 'test/19061',\n",
       " 'test/20001',\n",
       " 'test/20862',\n",
       " 'test/21202',\n",
       " 'test/21542',\n",
       " 'test/21573',\n",
       " 'training/10263',\n",
       " 'training/10308',\n",
       " 'training/10323',\n",
       " 'training/10337',\n",
       " 'training/10357',\n",
       " 'training/10358',\n",
       " 'training/10359',\n",
       " 'training/10364',\n",
       " 'training/10370',\n",
       " 'training/10382',\n",
       " 'training/10475',\n",
       " 'training/10546',\n",
       " 'training/10617',\n",
       " 'training/10650',\n",
       " 'training/10651',\n",
       " 'training/10652',\n",
       " 'training/10654',\n",
       " 'training/10659',\n",
       " 'training/10660',\n",
       " 'training/10679',\n",
       " 'training/10681',\n",
       " 'training/10684',\n",
       " 'training/10689',\n",
       " 'training/10696',\n",
       " 'training/10718',\n",
       " 'training/10736',\n",
       " 'training/10751',\n",
       " 'training/10762',\n",
       " 'training/10766',\n",
       " 'training/10769',\n",
       " 'training/10770',\n",
       " 'training/10771',\n",
       " 'training/10780',\n",
       " 'training/10804',\n",
       " 'training/10807',\n",
       " 'training/10809',\n",
       " 'training/11103',\n",
       " 'training/11203',\n",
       " 'training/11244',\n",
       " 'training/11734',\n",
       " 'training/11764',\n",
       " 'training/11772',\n",
       " 'training/11774',\n",
       " 'training/12136',\n",
       " 'training/12145',\n",
       " 'training/12396',\n",
       " 'training/12470',\n",
       " 'training/12780',\n",
       " 'training/12815',\n",
       " 'training/13315',\n",
       " 'training/13524',\n",
       " 'training/13530',\n",
       " 'training/13531',\n",
       " 'training/13544',\n",
       " 'training/14757',\n",
       " 'training/14767',\n",
       " 'training/14777',\n",
       " 'training/14779',\n",
       " 'training/1926',\n",
       " 'training/2178',\n",
       " 'training/2190',\n",
       " 'training/221',\n",
       " 'training/2286',\n",
       " 'training/2352',\n",
       " 'training/2354',\n",
       " 'training/2452',\n",
       " 'training/2633',\n",
       " 'training/3065',\n",
       " 'training/3419',\n",
       " 'training/3421',\n",
       " 'training/3433',\n",
       " 'training/3442',\n",
       " 'training/3532',\n",
       " 'training/3593',\n",
       " 'training/4616',\n",
       " 'training/4633',\n",
       " 'training/4675',\n",
       " 'training/4680',\n",
       " 'training/4686',\n",
       " 'training/4703',\n",
       " 'training/4709',\n",
       " 'training/4712',\n",
       " 'training/5070',\n",
       " 'training/5204',\n",
       " 'training/5206',\n",
       " 'training/5271',\n",
       " 'training/5290',\n",
       " 'training/5778',\n",
       " 'training/5798',\n",
       " 'training/5858',\n",
       " 'training/6108',\n",
       " 'training/6338',\n",
       " 'training/6357',\n",
       " 'training/7460',\n",
       " 'training/7538',\n",
       " 'training/7628',\n",
       " 'training/8153',\n",
       " 'training/8584',\n",
       " 'training/8588',\n",
       " 'training/8591',\n",
       " 'training/8607',\n",
       " 'training/8621',\n",
       " 'training/8657',\n",
       " 'training/8658',\n",
       " 'training/8664',\n",
       " 'training/8670',\n",
       " 'training/8710',\n",
       " 'training/8714',\n",
       " 'training/872',\n",
       " 'training/8735',\n",
       " 'training/8884',\n",
       " 'training/9007',\n",
       " 'training/9022',\n",
       " 'training/9061',\n",
       " 'training/9120',\n",
       " 'training/9128',\n",
       " 'training/9129',\n",
       " 'training/9134',\n",
       " 'training/9138',\n",
       " 'training/9149',\n",
       " 'training/9166',\n",
       " 'training/9213',\n",
       " 'training/9214',\n",
       " 'training/9216',\n",
       " 'training/9220',\n",
       " 'training/9222',\n",
       " 'training/9224',\n",
       " 'training/9282',\n",
       " 'training/9295',\n",
       " 'training/9689',\n",
       " 'training/9698',\n",
       " 'training/9701',\n",
       " 'training/9720',\n",
       " 'training/9764',\n",
       " 'training/9783',\n",
       " 'training/9792',\n",
       " 'training/9797',\n",
       " 'training/9862',\n",
       " 'training/9871',\n",
       " 'training/9946']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_docs([\"yen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieve_docs([\"yen\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: How many articles talk about Japan or Banks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieve_docs([\"japan\", \"banks\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Question 3: How many articles talk about England or Dealers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieve_docs([\"england\", \"dealers\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
