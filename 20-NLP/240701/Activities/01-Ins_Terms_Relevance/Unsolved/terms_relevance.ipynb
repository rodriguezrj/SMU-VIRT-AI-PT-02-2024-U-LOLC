{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk, numpy and pandas.\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import Reuters\n",
    "from nltk.corpus import reuters\n",
    "# Import CountVectorizer, TfidfVectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Download the Reuters dataset if you didn't install it.\n",
    "# nltk.download(\"reuters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "# Get the categories\n",
    "print(reuters.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of docs in the corpus: 10788\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of documents in the collection\n",
    "doc_ids = reuters.fileids()\n",
    "# Retrieve the number of documents in the corpus.\n",
    "print(f\"Total number of docs in the corpus: {len(doc_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the occurrence of each word in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STOCKS\n",
      "  A survey of 19 provinces and seven cities\n",
      "  showed vermin consume between seven and 12 pct of China's grain\n",
      "  stocks, the China Daily said.\n",
      "      It also said that each year 1.575 mln tonnes, or 25 pct, of\n",
      "  China's fruit output are left to rot, and 2.1 mln tonnes, or up\n",
      "  to 30 pct, of its vegetables. The paper blamed the waste on\n",
      "  inadequate storage and bad preservation methods.\n",
      "      It said the government had launched a national programme to\n",
      "  reduce waste, calling for improved technology in storage and\n",
      "  preservation, and greater production of additives. The paper\n",
      "  gave no further details.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select and print a single document of text.\n",
    "doc_text = reuters.raw(doc_ids[1])\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the CountVectorizer and define the English stopwords to be ignored.\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Tokenize the text into numerical features and occurrence of each word.\n",
    "X = vectorizer.fit_transform([doc_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t4\n",
      "  (0, 12)\t2\n",
      "  (0, 37)\t1\n",
      "  (0, 46)\t2\n",
      "  (0, 14)\t1\n",
      "  (0, 0)\t2\n",
      "  (0, 29)\t4\n",
      "  (0, 18)\t2\n",
      "  (0, 40)\t2\n",
      "  (0, 42)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 33)\t1\n",
      "  (0, 38)\t2\n",
      "  (0, 10)\t1\n",
      "  (0, 39)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 36)\t3\n",
      "  (0, 48)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 25)\t2\n",
      "  (0, 44)\t2\n",
      "  (0, 2)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 45)\t1\n",
      "  (0, 28)\t2\n",
      "  (0, 7)\t1\n",
      "  (0, 47)\t2\n",
      "  (0, 21)\t1\n",
      "  (0, 41)\t2\n",
      "  (0, 6)\t1\n",
      "  (0, 30)\t2\n",
      "  (0, 24)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 43)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 13)\t1\n"
     ]
    }
   ],
   "source": [
    "# X contains the occurrence of each term in the document.\n",
    "# We have 1 document, the first number in the tuple represents the document number, i.e., 0.\n",
    "# The second number in the tuple represents the index of the word in the vocabulary created by fit_transform.\n",
    "# The last number represents how many times the word appears.\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12' '19' '25' '30' '575' 'additives' 'bad' 'blamed' 'calling' 'china'\n",
      " 'cities' 'consume' 'daily' 'details' 'eat' 'fruit' 'gave' 'government'\n",
      " 'grain' 'greater' 'improved' 'inadequate' 'launched' 'left' 'methods'\n",
      " 'mln' 'national' 'output' 'paper' 'pct' 'preservation' 'production'\n",
      " 'programme' 'provinces' 'reduce' 'rot' 'said' 'says' 'seven' 'showed'\n",
      " 'stocks' 'storage' 'survey' 'technology' 'tonnes' 'vegetables' 'vermin'\n",
      " 'waste' 'year']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve unique words list\n",
    "words = vectorizer.get_feature_names_out()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "improved\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the words and find a specific word or term.\n",
    "print(len(words))\n",
    "print(words[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 2, 4, 2, 1, 1, 1, 1, 1, 3, 1, 2, 1, 2, 2, 1, 1,\n",
       "       2, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the number of times each word appears from the document. \n",
    "X.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>19</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>575</th>\n",
       "      <th>additives</th>\n",
       "      <th>bad</th>\n",
       "      <th>blamed</th>\n",
       "      <th>calling</th>\n",
       "      <th>china</th>\n",
       "      <th>cities</th>\n",
       "      <th>consume</th>\n",
       "      <th>daily</th>\n",
       "      <th>details</th>\n",
       "      <th>eat</th>\n",
       "      <th>fruit</th>\n",
       "      <th>gave</th>\n",
       "      <th>government</th>\n",
       "      <th>grain</th>\n",
       "      <th>greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   12  19  25  30  575  additives  bad  blamed  calling  china  cities  \\\n",
       "0   2   1   1   1    1          1    1       1        1      4       1   \n",
       "\n",
       "   consume  daily  details  eat  fruit  gave  government  grain  greater  \n",
       "0        1      2        1    1      1     1           1      2        1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the sparse matrix to a DataFrame to get our Bag-of-Words for the document. \n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(bow_df.shape)\n",
    "\n",
    "# Display some first 20 columns of the DataFrame.\n",
    "bow_df.iloc[:, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Word_Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Word_Counts\n",
       "0   12            2\n",
       "1   19            1\n",
       "2   25            1\n",
       "3   30            1\n",
       "4  575            1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melt the Bag-of-Words DataFrame to convert columns into rows.\n",
    "melted_bow = bow_df.melt(var_name='Word', value_name=\"Word_Counts\")\n",
    "melted_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Word_Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pct</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>said</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paper</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word  Word_Counts\n",
       "0  china            4\n",
       "1    pct            4\n",
       "2   said            3\n",
       "3     12            2\n",
       "4  paper            2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by Word_Counts if needed\n",
    "sorted_bow = melted_bow.sort_values(by='Word_Counts', ascending=False).reset_index(drop=True)\n",
    "sorted_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pct</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>said</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paper</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word  Word_Count\n",
       "0  china           4\n",
       "1    pct           4\n",
       "2   said           3\n",
       "3     12           2\n",
       "4  paper           2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively you can do the following:\n",
    "# Create a list to hold the words using the vectorizer.get_feature_names_out()\n",
    "words = list(vectorizer.get_feature_names_out())\n",
    "# Create a list to hold the frequency using np.ravel(X.sum(axis=0))\n",
    "frequency = list(np.ravel(X.sum(axis=0)))\n",
    "\n",
    "# Create a DataFrame of the TF–IDF weights for each word in the working corpus.\n",
    "words_df = pd.DataFrame({\n",
    "  \"Word\": words,\n",
    "  \"Word_Count\": frequency})\n",
    "\n",
    "# Alternatively you can use:\n",
    "# words_df = pd.DataFrame(list(zip(words, np.ravel(X.sum(axis=0)))), columns=[\"Word\", \"Word_Count\"])\n",
    "\n",
    "# Sort the DataFrame on the Word_Count in descending order and reset the index.\n",
    "sorted_words= words_df.sort_values(by=[\"Word_Count\"], ascending=False).reset_index(drop=True)\n",
    "sorted_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the TF-IDF score from a Corpus of Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NICKEL PRICES UNLIKELY TO RISE MUCH - SHEARSON\n",
      "  Nickel prices are unlikely to rise\n",
      "  significantly from current levels unless further steps are\n",
      "  taken to reduce production, Shearson Lehman Brothers said in\n",
      "  its quarterly nickel market report.\n",
      "      The market had recovered slightly to around 1.72 dlrs a lb\n",
      "  yesterday from its four year low of 1.55 dlrs in early January,\n",
      "  due to the absence of Soviet nickel cathode deliveries, but\n",
      "  Shearson sees Soviet shipments soon returning to last year's\n",
      "  buoyant levels, which should ease current tightness.\n",
      "      Output reductions by producers will take effect later this\n",
      "  year but are likely to be offset by increases elsewhere.\n",
      "      Shearson said the nickel market will be virtually in\n",
      "  balance during 1987, with total non-Socialist world demand at\n",
      "  556,000 tonnes, compared with an estimated 544,000 tonnes in\n",
      "  1986, production at 505,000 tonnes (504,000) and imports from\n",
      "  Socialist countries at 47,000 tonnes (50,000).\n",
      "      It forecast prices will edge higher during the year from a\n",
      "  first quarter average of 1.67 dlrs a lb up to 1.77 dlrs in the\n",
      "  last quarter. The year's average will be around 1.72 dlrs a lb\n",
      "  compared with 1.76 dlrs in 1986, using London Metal Exchange\n",
      "  cash metal prices in dollar terms and assuming an average 1987\n",
      "  sterling exchange rate of 1.55 dlrs.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the first 1000 articles from Reuters.\n",
    "corpus_id = doc_ids[0:1000]\n",
    "corpus = [reuters.raw(doc) for doc in corpus_id]\n",
    "\n",
    "# Print sample document\n",
    "print(corpus[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the TfidfVectorizer and define the English stopwords to be ignored.\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Tokenize the 1,000 articles into numerical features.\n",
    "X_corpus = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3653)\t0.02349374154800046\n",
      "  (0, 3572)\t0.03401531227145892\n",
      "  (0, 9282)\t0.023258637913775613\n",
      "  (0, 9251)\t0.02895058701961889\n",
      "  (0, 5736)\t0.031788665087932794\n",
      "  (0, 5876)\t0.04269766365167542\n",
      "  (0, 5004)\t0.02382046223442031\n",
      "  (0, 5281)\t0.04421016230849752\n",
      "  (0, 5595)\t0.04421016230849752\n",
      "  (0, 8051)\t0.03951191235503726\n",
      "  (0, 5798)\t0.037999413698215155\n",
      "  (0, 7395)\t0.04041700708351447\n",
      "  (0, 3186)\t0.07352722462649618\n",
      "  (0, 6900)\t0.03152282152841889\n",
      "  (0, 7263)\t0.03871356222491918\n",
      "  (0, 4079)\t0.031267012229669745\n",
      "  (0, 1746)\t0.04890841226195779\n",
      "  (0, 6009)\t0.04890841226195779\n",
      "  (0, 9449)\t0.04890841226195779\n",
      "  (0, 6839)\t0.03571875713005421\n",
      "  (0, 3204)\t0.029906837778906972\n",
      "  (0, 8301)\t0.036221071481879155\n",
      "  (0, 5719)\t0.03951191235503726\n",
      "  (0, 3623)\t0.04146186226670836\n",
      "  (0, 8287)\t0.04890841226195779\n",
      "  :\t:\n",
      "  (999, 6787)\t0.1736525446693858\n",
      "  (999, 7495)\t0.23299949141320167\n",
      "  (999, 7225)\t0.11157842602334765\n",
      "  (999, 6428)\t0.09972089581992193\n",
      "  (999, 2491)\t0.3605906417869579\n",
      "  (999, 7187)\t0.0868262723346929\n",
      "  (999, 6128)\t0.21786500994836006\n",
      "  (999, 3290)\t0.0927846852997494\n",
      "  (999, 9194)\t0.2991626874597658\n",
      "  (999, 2612)\t0.06803253161109463\n",
      "  (999, 2599)\t0.0687168948701313\n",
      "  (999, 3399)\t0.07955788050295923\n",
      "  (999, 7896)\t0.2189139803212712\n",
      "  (999, 1191)\t0.07399094457615113\n",
      "  (999, 2186)\t0.06643260003988805\n",
      "  (999, 1531)\t0.0789122642594043\n",
      "  (999, 9100)\t0.07447285813485557\n",
      "  (999, 336)\t0.05850728168318138\n",
      "  (999, 4516)\t0.07176615171901618\n",
      "  (999, 7887)\t0.14574226774139318\n",
      "  (999, 6495)\t0.03859748439867077\n",
      "  (999, 8308)\t0.05397476964595435\n",
      "  (999, 5538)\t0.05501440772298912\n",
      "  (999, 3391)\t0.03399422859269562\n",
      "  (999, 7680)\t0.025862490065704406\n"
     ]
    }
   ],
   "source": [
    "# Print the sparse matrix of the transformed data.\n",
    "# We have 1,000 documents, the first number in the tuple represents the document number.\n",
    "# The second number in the tuple represents the index of the word in the vocabulary created by fit_transform.\n",
    "# The last number represents the value of the TF-IDF score for the vocabulary word.\n",
    "print(X_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (1000, 9489)\n",
      "Total number of documents: 1000\n",
      "Total number of unique words (tokens): 9489\n"
     ]
    }
   ],
   "source": [
    "# Get the matrix info.\n",
    "print(f\"Matrix shape: {X_corpus.shape}\")\n",
    "print(f\"Total number of documents: {X_corpus.shape[0]}\")\n",
    "print(f\"Total number of unique words (tokens): {X_corpus.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.26172577, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_corpus.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '0000' ... 'zones' 'zurich' 'zy']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve words list from corpus\n",
    "words_corpus = vectorizer.get_feature_names_out()\n",
    "print(words_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vs</td>\n",
       "      <td>0.079701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mln</td>\n",
       "      <td>0.061460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cts</td>\n",
       "      <td>0.051221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000</td>\n",
       "      <td>0.047185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>said</td>\n",
       "      <td>0.045466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>net</td>\n",
       "      <td>0.038892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dlrs</td>\n",
       "      <td>0.038615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pct</td>\n",
       "      <td>0.028682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shr</td>\n",
       "      <td>0.027749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lt</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word    TF-IDF\n",
       "0    vs  0.079701\n",
       "1   mln  0.061460\n",
       "2   cts  0.051221\n",
       "3   000  0.047185\n",
       "4  said  0.045466\n",
       "5   net  0.038892\n",
       "6  dlrs  0.038615\n",
       "7   pct  0.028682\n",
       "8   shr  0.027749\n",
       "9    lt  0.027100"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the TF-IDF weights of each word in corpus as DataFrame\n",
    "words_corpus_df = pd.DataFrame(\n",
    "    list(zip(words_corpus, np.ravel(X_corpus.mean(axis=0)))), columns=[\"Word\", \"TF-IDF\"])\n",
    "\n",
    "# Sort the DataFrame to show the top TF-IDF values.\n",
    "sorted_words_corpus = words_corpus_df.sort_values(by=[\"TF-IDF\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Highest 10 TF-IDF scores\n",
    "sorted_words_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9479</th>\n",
       "      <td>denotes</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>modification</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9481</th>\n",
       "      <td>bulgur</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>cracked</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9483</th>\n",
       "      <td>019</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9484</th>\n",
       "      <td>302</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>893</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9486</th>\n",
       "      <td>927</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9487</th>\n",
       "      <td>076</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488</th>\n",
       "      <td>rolled</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word    TF-IDF\n",
       "9479       denotes  0.000005\n",
       "9480  modification  0.000005\n",
       "9481        bulgur  0.000005\n",
       "9482       cracked  0.000005\n",
       "9483           019  0.000005\n",
       "9484           302  0.000005\n",
       "9485           893  0.000005\n",
       "9486           927  0.000005\n",
       "9487           076  0.000005\n",
       "9488        rolled  0.000005"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowest 10 TF-IDF scores\n",
    "sorted_words_corpus.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
